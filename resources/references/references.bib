
# OTHER INSTERSTING RESOURCES 
* Growing up with AI : Cognimates : from coding to teaching machines 
https://dspace.mit.edu/handle/1721.1/120691 


* Growing up with AI
https://leidenlawblog.nl/articles/growing-up-with-ai


@book{pearce2013open,
  title={Open-Source Lab: How to Build Your Own Hardware and Reduce Research Costs},
  author={Pearce, J.M.},
  isbn={9780124104860},
  lccn={2013035658},
  url={https://books.google.co.uk/books?id=0bOKAAAAQBAJ},
  year={2013},
  publisher={Elsevier Science}
}



@article{tarik2017,
author = {T. Mohammad, Farah and Mohammad, Farah and Mohammad, Mohammad and Tarik Al Ali, Zahraa},
year = {2017},
month = {08},
pages = {},
title = {A Hybrid Spiral Project Based Learning Model for Microprocessor Course Teaching},
doi = {10.24017/science.2017.3.36}
}



# MAIN REFENCES  

@online{UNICEF2020,
  author =       "United Nations Children's Fund (UNICEF)",
  year =         "2020",
  title =        "Policy guidance on AI for children, DRAFT 1.0 ",
  url =          "https://www.unicef.org/globalinsight/reports/policy-guidance-ai-children ",
  month =        jan,
  lastaccessed = "January 24, 2021",
}


@inproceedings{hu2018,
author = {Ku, Hyunjin and Choi, Jason J. and Lee, Soomin and Jang, Sunho and Do, Wonkyung},
title = {Shelly, a Tortoise-Like Robot for One-to-Many Interaction with Children},
year = {2018},
isbn = {9781450356152},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173386.3177824},
doi = {10.1145/3173386.3177824},
abstract = {We designed "Shelly", a robot interacting with children while restraining children»s robot abusing behaviors. Shelly has a tortoise-like friendly appearance and touch based simple and versatile interface, which encourages children to interact with the robot spontaneously in environments such as amusement park or kindergarten. We have developed two prototypes and proved validity of Shelly»s social concepts - one-to-many interaction and restraining robot abusing - through field tests. Ultimately, Shelly»s novel interface and interaction model targeted for multiple-children interaction would effectively attribute to various social goods.},
booktitle = {Companion of the 2018 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {353–354},
numpages = {2},
keywords = {multi-modal interface, one-to-many interaction, non-verbal interface, robot abusing, animal-like robot},
location = {Chicago, IL, USA},
series = {HRI '18}
}



@online{opensource2021,
  author =       "Opensource.com",
  year =         "2021",
  title =        "What is open source? ",
  url =          "https://opensource.com/resources/what-open-source",
  month =        jan,
  lastaccessed = "March 03 2021",
}




@Phdthesis{Serholt:2017,
  author = "Serholt, Sofia",
  year =         "2017",
  title =        "Child–Robot Interaction in Education",
  school =       "University of Gothenburg",
  address =      "Gothenburg, Germany",
  isbn = {978-91-88245-00-7},
  type =         "",
  month =        "",
}


@online{OttoDIY:2016,
  author =       "Parra-Palacio, Camilo and Svarcova, Tereza and Clime, Ethan",
  year =         "2016",
  title =        "Otto DIY robots",
  url =          "https://www.ottodiy.com/",
  month =        Jan,
  lastaccessed = "Jan 31, 2021",
}


@online{OSR:2018,
  author =       "NASA Jet Propulsion Laboratory",
  year =         "2018",
  title =        "Open Source Rover",
  url =          "https://github.com/nasa-jpl/open-source-rover",
  month =        April,
  lastaccessed = "Jan 31, 2021",
}


@online{nanoJetBot:2019,
  author =       "NVIDIA",
  year =         "2019",
  title =        "Nano JetBot",
  url =          "https://github.com/NVIDIA-AI-IOT/jetbot",
  month =         March,
  lastaccessed = "Jan 31, 2021",
}




@online{sparky2012,
  author =       "ArcBotics",
  year =         "2012",
  title =        "Sparky: a platform to learn robotics, programming, and electronics",
  url =          "http://arcbotics.com/products/sparki/",
  lastaccessed = "March 03, 2021",
}




@online{savage2020,
  author =       "Savage Neil ",
  year =         "2020",
  title =        "The race to the top among the world’s leaders in artificial intelligence",
  url =          "https://www.nature.com/articles/d41586-020-03409-8",
  month =         December,
  lastaccessed = "Feb 02, 2021",
}
 


@inproceedings {durr2015,
booktitle = {EG 2015 - Posters},
editor = {B. Solenthaler and E. Puppo},
title = {{Deep Learning on a Raspberry Pi for Real Time Face Recognition}},
author = {Durr, Oliver and Pauchard, Yves and Browarnik, Diego and Axthelm, Rebekka and Loeser, Martin},
year = {2015},
publisher = {The Eurographics Association},
DOI = {10.2312/egp.20151036}
}


@misc{matelabs2017,
  title  = "Why do we need the Democratization of Machine Learning?",
  author = "MateLabs",
  year = {2017},
  Howpublished = {\url{https://medium.com/startup-grind/why-do-we-need-the-democratization-of-machine-learning-80104e43c76f}},
  note = {April 27, 2017 (accessed December 08, 2017)},
}




@Inbook{ruiz-garcia2016,
author="Ruiz-Garcia, Ariel
and Elshaw, Mark
and Altahhan, Abdulrahman
and Palade, Vasile",
editor="Villa, Alessandro E.P.
and Masulli, Paolo
and Pons Rivero, Antonio Javier",
title="Deep Learning for Emotion Recognition in Faces",
bookTitle="Artificial Neural Networks and Machine Learning -- ICANN 2016: 25th International Conference on Artificial Neural Networks, Barcelona, Spain, September 6-9, 2016, Proceedings, Part II",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="38--46",
abstract="Deep Learning (DL) has shown real promise for the classification efficiency for emotion recognition problems. In this paper we present experimental results for a deeply-trained model for emotion recognition through the use of facial expression images. We explore two Convolutional Neural Network (CNN) architectures that offer automatic feature extraction and representation, followed by fully connected softmax layers to classify images into seven emotions. The first architecture explores the impact of reducing the number of deep learning layers and the second splits the input images horizontally into two streams based on eye and mouth positions. The first proposed architecture produces state of the art results with an accuracy rate of 96.93 {\%} and the second architecture with split input produces an average accuracy rate of 86.73 {\%}, respectively.",
isbn="978-3-319-44781-0",
doi="10.1007/978-3-319-44781-0_5",
url="https://doi.org/10.1007/978-3-319-44781-0_5"
}



@misc{ho2016,
author = {Jostine Ho},
title = {Facial Emotion Recognition},
year = {2016},
publisher = {GitHub},
journal = {GitHub repository},
Howpublished = {\url{https://github.com/JostineHo/mememoji}},
note = {Accessed December 08, 2017},
}
commit = {d2c2f7892281849cc632b9f85367f0a2b62ec098},




@book{montessori2013absorbent,
  title={The Absorbent Mind},
  author={Montessori, M.},
  isbn={9781625588685},
  url={https://books.google.co.uk/books?id=4OrsAgAAQBAJ},
  year={2013},
  series={Unabridged Start Publishing LLC},
  publisher={Start Publishing LLC}
}


@article{elkin2014,
author = {Elkin, Mollie and Sullivan, Amanda and Bers, Marina},
year = {2014},
month = {01},
pages = {153-169},
title = {Implementing a Robotics Curriculum in an Early Childhood Montessori Classroom},
volume = {13},
journal = {Journal of Information Technology Education: Innovations in Practice},
doi = {10.28945/2094}
}



@book{bers2008,
  title={Blocks to Robots: Learning with Technology in the Early Childhood Classroom},
  author={Bers, M.U.},
  isbn={9780807748473},
  lccn={2007028960},
  url={https://books.google.co.uk/books?id=KkUmAQAAIAAJ},
  year={2008},
  publisher={Teachers College Press}
}

@book{bers2012,
 author = {Bers, Marina Umaschi},
 title = {Designing Digital Experiences for Positive Youth Development: From Playpen to Playground},
 year = {2012},
 isbn = {9780199757022},
 edition = {1st},
 publisher = {Oxford University Press},
 address = {Boston, MA, USA},
}

@inbook{bers-horn2010,
title = "Tangible Programming in Early Childhood: Revisiting Developmental Assumptions Through New Technologies",
author = "Bers, {Marina Umaschi} and Horn, {Michael S.}",
year = "2010",
language = "English",
isbn = "978-1617350092",
series = "Research in Global Child Advocacy",
publisher = "Information Age Publishing",
pages = "49--70",
editor = "Berson, {Ilene R.} and Berson, {Michael J.}",
booktitle = "High-Tech Tots",
}


@article{kazakoff-bers2012,
  title={Programming in a Robotics Context in the Kindergarten Classroom: The Impact on Sequencing Skills},
  author={Elizabeth R. Kazakoff and M. Bers},
  journal={Journal of Educational Multimedia and Hypermedia},
  year={2012},
  volume={21},
  pages={371-391}
}



@inproceedings{resnick1998,
author = {Resnick, Mitchel and Martin, Fred and Berg, Robert and Borovoy, Rick and Colella, Vanessa and Kramer, Kwin and Silverman, Brian},
title = {Digital Manipulatives: New Toys to Think With},
year = {1998},
isbn = {0201309874},
publisher = {ACM Press/Addison-Wesley Publishing Co.},
address = {USA},
url = {https://doi.org/10.1145/274644.274684},
doi = {10.1145/274644.274684},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {281–287},
numpages = {7},
keywords = {children, learning, education, ubiquitous computing},
location = {Los Angeles, California, USA},
series = {CHI '98}
}






@article{gaudeul2007,
author = {Gaudeul, Alexia},
year = {2007},
month = {06},
pages = {},
title = {Do Open Source Developers Respond to Competition? The LaTeX Case Study},
volume = {6},
journal = {Review of Network Economics},
doi = {10.2202/1446-9022.1119}
}



@book{brasseur2018,
  title={Forge Your Future with Open Source: Build Your Skills. Build Your Network. Build the Future of Technology.},
  author={Brasseur, VM},
  isbn={9781680506396},
  url={https://books.google.co.uk/books?id=Tm15DwAAQBAJ},
  year={2018},
  publisher={Pragmatic Bookshelf}
}


@Article{stallman1985,
  author =       "Richard Stallman",
  title =        "The {GNU} Manifesto",
  journal =      j-DDJ,
  volume =       "10",
  number =       "3",
  pages =        "30--??",
  month =        mar,
  year =         "1985",
  CODEN =        "DDJOEB",
  ISSN =         "1044-789X",
  bibdate =      "Mon Sep 2 09:09:39 MDT 1996",
  bibsource =    "http://www.ddj.com/index/author/index.htm",
  acknowledgement = ack-nhfb,
}


@book{pearce2013,
  title={Open-Source Lab: How to Build Your Own Hardware and Reduce Research Costs},
  author={Pearce, J.M.},
  isbn={9780124104860},
  lccn={2013035658},
  url={https://books.google.co.uk/books?id=0bOKAAAAQBAJ},
  year={2013},
  publisher={Elsevier Science}
}










@article{druga2019,
abstract = {We observed how 102 children (7-12 years old), from four different countries (U.S.A, Germany, Denmark, and Sweden), imagine smart devices and toys of the future and how they perceive current AI technologies. Children outside of U.S.A were overall more critical of these technologies and less exposed to them. The way children collaborated and communicated while describing their AI perception and expectations were influenced both by their social-economical and cultural background. Children in low and medium SES schools and centers were better are collaborating compared to high SES children, but had a harder time advancing because they had less experience with coding and interacting with these technologies. Children in high SES schools and centers had troubles collaborating initially but displayed a stronger understanding of AI concepts. Based on our initial findings we propose a series of guidelines for designing future hands-on learning activities with smart toys and AI devices for K8 students.},
author = {Druga, Stefania and Vu, Sarah T. and Likhith, Eesh and Qiu, Tammy},
doi = {10.1145/3311890.3311904},
file = {/[doi 10.1145_3311890.3311904] Druga, Stefania\; Vu, Sarah T.\; Likhith, Eesh\; Qiu, Tammy -- [ACM Press FabLearn 2019 - New York, NY, USA (2019.03.09-2019.03.10)] Proceedings of FabLearn 2019 on - FL20.pdf:pdf},
isbn = {9781450362443},
journal = {ACM International Conference Proceeding Series},
keywords = {AI literacy,Child-Agent Interaction,Inclusive education},
pages = {104--111},
title = {{Inclusive AI literacy for kids around the world}},
year = {2019}
}

@article{Lupetti2017,
abstract = {This article presents Shybo: a novel low-anthropomorphic robot for children. The robot, resulted from the combination of open-source hardware and software, is able to perceive sounds and to react through two non-verbal behaviors: hat's movement and lighting. By taking advantage of an open-source machine-learning software, the robot can be easily trained by children. This robot can be employed in research to support human-robot interaction studies with children, for investigating perceptual aspects of robot's features or for investigating children' cognitive abilities. It can also be used for applications in educational context to support playful learning experiences.},
author = {Lupetti, Maria Luce},
doi = {10.1016/j.ohx.2017.08.003},
issn = {24680672},
journal = {HardwareX},
keywords = {3D printing,Child-robot interaction,Machine-learning,Open design,Open hardware},
pages = {50--60},
publisher = {The Author},
title = {{Shybo. An open-source low-anthropomorphic robot for children}},
url = {https://doi.org/10.1016/j.ohx.2017.08.003},
volume = {2},
year = {2017}
}




